import torch
from datasets import load_dataset
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
)
from peft import LoraConfig
from trl import SFTTrainer, SFTConfig

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
MODEL_ID = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
NEW_MODEL_NAME = "uos-eng-v3"  # V3 ëª¨ë¸ (ë¬¸ì œ í•´ê²°)
DATASET_FILE = "train_eng_v3.jsonl"  # V3 ë°ì´í„°ì…‹ (ê³µê²© 200:ì •ìƒ 200)

# ==========================================
# 2. ë°ì´í„°ì…‹ ë¡œë“œ ë° í¬ë§·íŒ… (ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì •ë¨)
# ==========================================
dataset = load_dataset("json", data_files=DATASET_FILE, split="train")

def formatting_prompts_func(example):
    output_texts = []
    
    # ğŸš¨ [ìˆ˜ì • ì™„ë£Œ] ë°ì´í„°ê°€ í•˜ë‚˜ì”© ë“¤ì–´ì˜¤ë¯€ë¡œ ì´ì¤‘ ë£¨í”„ë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤.
    # example['messages']ëŠ” [{'role': 'user'...}, {'role': 'assistant'...}] í˜•íƒœì…ë‹ˆë‹¤.
    conversation = example['messages']
    
    text = ""
    for msg in conversation:
        role = msg['role']
        content = msg['content']
        
        if role == "user":
            text += f"<|user|>\n{content}</s>\n"
        elif role == "assistant":
            text += f"<|assistant|>\n{content}</s>\n"
            
    output_texts.append(text)
    return output_texts

# ==========================================
# 3. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ (QLoRA)
# ==========================================
print("â³ ëª¨ë¸ ë¡œë“œ ì¤‘...")
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    quantization_config=bnb_config,
    device_map="auto"
)

tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)
tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = "right"

peft_config = LoraConfig(
    lora_alpha=16,
    lora_dropout=0.1,
    r=8,  # Rank
    bias="none",
    task_type="CAUSAL_LM",
)

# ==========================================
# 4. í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • (ì•ˆì „ ëª¨ë“œ ì ìš©)
# ==========================================
# ğŸš¨ max_seq_length ì—ëŸ¬ë¥¼ í”¼í•˜ê¸° ìœ„í•´ initì—ì„œ ë¹¼ê³  ì•„ë˜ì—ì„œ ì£¼ì…í•©ë‹ˆë‹¤.
training_args = SFTConfig(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    optim="paged_adamw_32bit",
    save_steps=50,
    logging_steps=10,
    learning_rate=2e-4,
    weight_decay=0.001,
    fp16=False,
    bf16=False,
    max_grad_norm=0.3,
    max_steps=-1,
    warmup_ratio=0.03,
    group_by_length=True,
    lr_scheduler_type="constant",
    dataset_text_field="text", 
)

# ê°•ì œ ì£¼ì… (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ê·¸/ë²„ì „ ì´ìŠˆ ë°©ì§€)
training_args.max_seq_length = 512

# ==========================================
# 5. íŠ¸ë ˆì´ë„ˆ ì‹¤í–‰
# ==========================================
trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    peft_config=peft_config,
    formatting_func=formatting_prompts_func,
    processing_class=tokenizer, # tokenizer ëŒ€ì‹  processing_class ì‚¬ìš©
    args=training_args,
)

print("ğŸš€ í•™ìŠµ ì‹œì‘!")
trainer.train()

# ==========================================
# 6. ì €ì¥
# ==========================================
print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
trainer.model.save_pretrained(NEW_MODEL_NAME)
tokenizer.save_pretrained(NEW_MODEL_NAME)
print(f"ğŸ‰ í•™ìŠµ ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: ./{NEW_MODEL_NAME}")